{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from utils import generate_dataset, get_normalized_adj, calculate_random_walk_matrix, nb_zeroinflated_nll_loss\n",
    "from model import *\n",
    "import copy\n",
    "import pickle as pk\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "#PARAMETERS\n",
    "torch.manual_seed(0)\n",
    "device = torch.device('mps') if torch.backends.mps.is_available() else torch.device('cpu')\n",
    "# Adjacency matrix\n",
    "A = np.load('A.npy')\n",
    "# Data\n",
    "X = np.load('X.npy')\n",
    "\n",
    "num_timesteps_output, num_timesteps_input = 4, 4\n",
    "space_dim = X.shape[1] # number of stops\n",
    "batch_size = 4\n",
    "hidden_dim_s = 70\n",
    "hidden_dim_t = 7\n",
    "rank_s = 20\n",
    "rank_t = 4\n",
    "epochs = 500"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "device(type='mps')"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "# Initial networks\n",
    "# B_TCN: bidirectional temporal convolution network\n",
    "TCN1 = B_TCN(space_dim,hidden_dim_t, kernel_size=3, device='mps').to(device)\n",
    "TCN2 = B_TCN(hidden_dim_t, rank_t, kernel_size=3, activation='linear', device='mps').to(device)\n",
    "TCN3 = B_TCN(rank_t, hidden_dim_t, kernel_size=3, device='mps').to(device)\n",
    "\n",
    "TNB = NBNorm_ZeroInflated(hidden_dim_t, space_dim).to(device)\n",
    "\n",
    "# D_GCN: diffusion graph convolution\n",
    "SCN1 = D_GCN(num_timesteps_input, hidden_dim_s, 3).to(device)\n",
    "SCN2 = D_GCN(hidden_dim_s, rank_s, 2, activation='linear').to(device)\n",
    "SCN3 = D_GCN(rank_s, hidden_dim_s, 2).to(device)\n",
    "\n",
    "SNB = NBNorm_ZeroInflated(hidden_dim_s, num_timesteps_output).to(device)\n",
    "\n",
    "STmodel = ST_NB_ZeroInflated(SCN1, SCN2, SCN3, TCN1, TCN2, TCN3, SNB, TNB).to(device)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "X = X.T\n",
    "X = X.astype(np.float32)\n",
    "X = X.reshape((X.shape[0], 1, X.shape[1])) # X is of shape (node number, 1, number of time steps)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3052, 1, 410) (410, 410)\n"
     ]
    }
   ],
   "source": [
    "split_line1 = int(X.shape[2]*0.6)\n",
    "split_line2 = int(X.shape[2]*0.7)\n",
    "print(X.shape, A.shape)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [
    "# Normalization\n",
    "max_value = np.max(X[:,:,:split_line1])\n",
    "\n",
    "train_original_data = X[:,:,:split_line1]\n",
    "val_original_data = X[:,:, split_line1: split_line2]\n",
    "test_original_data = X[:,:, split_line2:]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input shape:  torch.Size([239, 3052, 4, 1]) torch.Size([34, 3052, 4, 1]) torch.Size([116, 3052, 4, 1])\n"
     ]
    }
   ],
   "source": [
    "training_input, training_target = generate_dataset(train_original_data, num_timesteps_input=num_timesteps_input, num_timesteps_output=num_timesteps_output)\n",
    "val_input, val_target = generate_dataset(val_original_data, num_timesteps_input=num_timesteps_input, num_timesteps_output=num_timesteps_output)\n",
    "test_input, test_target = generate_dataset(test_original_data, num_timesteps_input=num_timesteps_input, num_timesteps_output=num_timesteps_output)\n",
    "\n",
    "print('input shape: ', training_input.shape, val_input.shape, test_input.shape)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [],
   "source": [
    "A_wave = get_normalized_adj(A)\n",
    "A_q = torch.from_numpy((calculate_random_walk_matrix(A_wave).T).astype('float32'))\n",
    "A_h = torch.from_numpy((calculate_random_walk_matrix(A_wave.T).T).astype('float32'))\n",
    "\n",
    "A_q = A_q.to(device)\n",
    "A_h = A_h.to(device)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(STmodel.parameters(), lr=1e-5)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [],
   "source": [
    "training_nll = []\n",
    "validation_nll = []\n",
    "validation_mae = []"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for epoch in range(epochs):\n",
    "    #Training\n",
    "    permutation = torch.randperm(training_input.shape[0])\n",
    "    epoch_training_losses = []\n",
    "    for i in range(0, training_input.shape[0], batch_size):\n",
    "        STmodel.train()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        indices = permutation[i:i+batch_size]\n",
    "        X_batch, y_batch = training_input[indices], training_target[indices]\n",
    "        X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "\n",
    "        n_train, p_train, pi_train = STmodel(X_batch, A_q, A_h)\n",
    "        loss = nb_zeroinflated_nll_loss(y_batch, n_train, p_train, pi_train)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_training_losses.append(loss.detach().cpu().numpy())\n",
    "\n",
    "    training_nll.append(sum(epoch_training_losses)/len(epoch_training_losses))\n",
    "\n",
    "    #Validation\n",
    "    with torch.no_grad():\n",
    "        STmodel.eval()\n",
    "        val_input = val_input.to(device)\n",
    "        val_target = val_target.to(device)\n",
    "\n",
    "        n_val, p_val, pi_val = STmodel(val_input, A_q, A_h)\n",
    "        print('Pi_val, mean, min, max ', torch.mean(pi_val), torch.min(pi_val), torch.max(pi_val))\n",
    "        val_loss = nb_zeroinflated_nll_loss(val_target, n_val, p_val, pi_val).to(device)\n",
    "        validation_nll.append(val_loss.detach().numpy().item())\n",
    "\n",
    "        #Calculate the expectation value\n",
    "        val_pred = (1-pi_val.detach().cpu().numpy()) * (n_val.detach().cpu().numpy() / p_val.detach().cpu().numpy() - n_val.detach().cpu().numpy())\n",
    "        print(val_pred.mean(), pi_val.detach().cpu().numpy().min())\n",
    "        mae = np.mean(np.abs(val_pred-val_target.detach().cpu().numpy()))\n",
    "        validation_mae.append(mae)\n",
    "\n",
    "        n_val, p_val, pi_val = None, None, None\n",
    "        val_input = val_input.to(device='cpu')\n",
    "        val_target = val_target.to(device='cpu')\n",
    "\n",
    "    print('Epoch: {}'.format(epoch))\n",
    "    print('Training loss: {}'.format(training_nll[-1]))\n",
    "    print('Epoch %d: trainNLL %.5f; valNLL %.5f; mae %.4f' % (epoch, training_nll[-1], validation_nll[-1], validation_mae[-1]))\n",
    "\n",
    "    if training_nll[-1].item() == min(training_nll):\n",
    "        best_model = copy.deepcopy(STmodel.state_dict())\n",
    "    checkpoint_path = \"checkpoints/\"\n",
    "    if not os.path.exists(checkpoint_path):\n",
    "        os.makedirs(checkpoint_path)\n",
    "    with open(\"checkpoints/losses.pk\", 'wb') as fd:\n",
    "        pk.dump((training_nll, validation_nll, validation_mae), fd)\n",
    "    if np.isnan(training_nll[-1]):\n",
    "        break"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
